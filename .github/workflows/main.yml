name: Generate Transcript and Upload

on:
  workflow_dispatch:    # manual trigger
  push:                 # triggers on every push
    branches:
      - main

jobs:
  generate_transcript:
    name: Generate Transcript (Python 3.12)
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v3

    - name: Set up Python 3.12
      uses: actions/setup-python@v4
      with:
        python-version: '3.12'

    - name: Cache LLaMA model
      uses: actions/cache@v3
      with:
        path: models/Meta-Llama-3-8B-Instruct.Q4_0.gguf
        key: llama-model-v1

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install gpt4all gdown telebot

    - name: Download model if not cached
      run: |
        if [ ! -f models/Meta-Llama-3-8B-Instruct.Q4_0.gguf ]; then
          mkdir -p models
          echo "ðŸ“¥ Downloading model..."
          python -m gdown https://drive.google.com/uc?id=1c2XOp78-KgIECyMWpvhKyDVj74KiFv5L -O models/Meta-Llama-3-8B-Instruct.Q4_0.gguf --fuzzy --resume
        else
          echo "âœ… Model found in cache"
        fi

    - name: Generate transcripts
      run: python generate_transcript.py
      env:
        C_ID: ${{ secrets.CHAT_ID }}
        TOKEN: ${{ secrets.TOKEN }}
